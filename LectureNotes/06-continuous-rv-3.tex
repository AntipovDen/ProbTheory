\documentclass[12pt]{article}

\usepackage{a4wide}

\usepackage[utf8]{inputenc} 
\usepackage[russian]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{pgfplots}
\usepgfplotslibrary{statistics,patchplots}
\usetikzlibrary{decorations.pathreplacing,calc,tikzmark, patterns,arrows.meta}
\pgfmathdeclarefunction{gauss}{3}{%
  \pgfmathparse{1/(#3*sqrt(2*pi))*exp(-((#1-#2)^2)/(2*#3^2))}%
}
\pgfmathdeclarefunction{gauss2d}{6}{%
  \pgfmathparse{1/(#3*#6*2*pi)*exp(-((#1-#2)^2)/(2*#3^2) - ((#4-#5)^2)/(2*#6^2))}%
}

\usepackage{xspace}

\usepackage{mathtools}
\usepackage{cite}
\usepackage{array}
\usepackage{multirow}
\usepackage{tabularx}

\newcommand\N{\mathbb{N}}
\newcommand\R{\mathbb{R}}
\newcommand\eps{\varepsilon}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Geom}{Geom}
\DeclareMathOperator{\pow}{pow}
\DeclareMathOperator{\Bern}{Bern}
\DeclareMathOperator{\Exp}{Exp}
\DeclareMathOperator{\Var}{Var}


\title{Лекция 6. Непрерывные с.в., часть 3}

\begin{document}
\maketitle


Закончили на определении плотности вероятности с.в. $X$ при известном значении с.в. $Y$.

\begin{align*}
  \Pr(X \in A \mid Y = y) = \int_A f_{X \mid Y}(x \mid y) dx,
\end{align*}
И ее свойствах:
\begin{itemize}
  \item $f_{X \mid Y}(x \mid y) \ge 0$
  \item $\int_{-\infty}^{+\infty} f_{X \mid Y}(x \mid y) dx = \frac{\int_{-\infty}^{+\infty} f_{X, Y}(x \mid y) dx}{f_Y(y)} = 1$
\end{itemize}

Еще раз подчеркнем, что стоит воспринимать условную плотность как срез совместной плотности по какому-то значению с.в.. Заметьте, что при этом вероятность этого среза равна нулю (одномерное множество), поэтому только терминами условности на события тут не обойтись.

Работает правило умножения:
\begin{align*}
  f_{X, Y} (x, y) &= f_X(x) f_{Y \mid X}(y \mid x) \\
                  &= f_Y(y) f_{X \mid Y}(x \mid y) \\
\end{align*}

А значит, работают полные вероятность и матожидание. Полная вероятность (следует из правила умножения и определения маргинальной плотности вероятности):
\begin{align*}
  f_X(x) = \int_{-\infty}^{+\infty} f_Y(y) f_{X \mid Y}(x\mid y) dy
\end{align*}
Также определено условное матожидание
\begin{align*}
  E(X \mid Y = y) = \int_{-\infty}^{+\infty} x f_{X \mid Y}(x \mid y) dx
\end{align*}
и работает теорема о полном матожидании:
\begin{align*}
  E(X) &= \int_{-\infty}^{+\infty} x f_{X}(x) dx = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x f_Y(y) f_{X \mid Y}(x\mid y) dy dx \\
       &= \int_{-\infty}^{+\infty}  f_Y(y) \left(\int_{-\infty}^{+\infty} x f_{X \mid Y}(x\mid y) dx\right) dy \\
       &= \int_{-\infty}^{+\infty} f_{Y}(y)E(X \mid Y = y) dy
\end{align*}

Также можно посчитать условное матожидание функции с.в.
\begin{align*}
  E(g(X) \mid Y = y) = \int_{-\infty}^{+\infty} g(x) f_{X \mid Y}(x, y) dx
\end{align*}

\section{Независимость с.в.}

Было у дискретных:

\begin{align*}
  p_{X, Y}(x, y) = p_X(x)p_Y(y)
\end{align*}

Логично определить непрерывные с.в. $X$ и $Y$ независимыми, если

\begin{align*}
  f_{X, Y}(x, y) = f_X(x) f_Y(y)
\end{align*}

Это автоматически подразумевает, что для всех $y$ верно, что $f_{X \mid Y}(x \mid y) = f_X(x)$.

Свойства независимых с.в. те же, что и у дискретных
\begin{itemize}
  \item $E(XY) = E(X) E(Y)$
  \item $\Var(X + Y) = \Var(X) + \Var(Y)$
  \item $g(X)$ и $h(Y)$ тоже будут независимы  
\end{itemize}

\textbf{Пример независимых с.в.}

Пусть есть два трамвая, которые ходят с интервалом 11 и 17 минут, независимо друг от друга. Вы приходите на остановку в случайный момент времени. Сколько ожидаемо вы будете ожидать трамвай, если вам подходит любой из двух?

Определим с.в. Пусть $T_1$ --- время, через которое придет первый трамвай, а $T_2$ --- второй. Заметим, что $T_1 \sim U(0, 11)$, а $T_2 \sim U(0, 17)$, то есть
\begin{align*}
  F_{T_1}(t) &= \begin{cases}
    0, t < 0 \\
    \frac{t}{11}, t \in [0, 11] \\
    1, t > 11,
  \end{cases} \\
  F_{T_2}(t) &= \begin{cases}
    0, t < 0 \\
    \frac{t}{17}, t \in [0, 17] \\
    1, t > 17,
  \end{cases}
\end{align*}

А время, которое придется провести на остановке есть $Y = \min\{T_1, T_2\}$, функция от двух независимых с.в.

Определим функцию распределения $Y$.
\begin{align*}
  F_Y(y) &= \Pr(Y \le y) = \Pr(T_1 \le y \cup T_2 \le y) \\
         &= 1 - \Pr(T_1 > y \cap T_2 > y) \\
         &= 1 - \Pr(T_1 > y) \Pr(T_2 > y) = 1 - (1 - F_{T_1}(y))(1 - F_{T_2}(y))
\end{align*}

Воспользуемся полезной формулой с прошлой практики для неотрицательных с.в. (\emph{которую доказали не все})
\begin{align*}
  E(Y) &= \int_{0}^{+\infty} (1 - F_Y(y)) dy = \int_{0}^{+\infty} (1 - F_{T_1}(y))(1 - F_{T_2}(y))dy \\
  &= \int_{0}^{11} \left(1 - \frac{y}{11}\right)\left(1 - \frac{y}{17}\right) dy \approx 4.31
\end{align*}



\textbf{Пример про зависимые с.в.}

Есть палка длиной $\ell$. Ломаем ее в случайном месте $X\in [0, \ell]$, остаток тоже ломаем в случайном месте $Y \in [0, X]$. Какова длина остатка $Y$? Заметим, что величины зависимы: если $X \ge \ell/2$, то есть шанс, что $Y \ge \ell/2$, а иначе нет.

Совместная функция распределения:

\begin{align*}
  f_{X, Y} (x, y) = f_X(x) f_{Y \mid X}(y \mid x) = \frac{1}{\ell x}
\end{align*}

Теперь можем найти плотность вероятности $Y$ и его матожидание. Для этого интегрируем совместную ПВ по всем возможным $X$, то есть от $y$ до $\ell$ 
\begin{align*}
  f_Y(y) = \int_y^\ell f_{X, Y} (x, y) dx = \int_0^\ell \frac{1}{\ell x} dx = \frac{1}{\ell} \ln\frac{\ell}{y}.
\end{align*}

Два способа посчитать матожидание. Первый:
\begin{align*}
  E(Y) = \int_0^\ell y f_Y(y)dy = \int_0^\ell \frac{y}{\ell} \ln\frac{\ell}{y} dy = \left( \frac{\ln(\ell)}{\ell} \cdot \frac{y^2}{2} - \frac{y^2 \ln(y)}{2\ell} + \frac{y^2}{4\ell}\right) \bigg|_0^\ell = \frac{\ell}{4}
\end{align*}

Второй:
\begin{align*}
  E(Y) = \int_0^\ell f_X(x) E(Y \mid X = x) dx = \int_0^\ell \frac{1}{\ell} \cdot \frac{x}{2} dx = \frac{x^2}{4\ell} \bigg|_0^\ell = \frac{\ell}{4}
\end{align*}

Интуитивная логика: первый раз палка ломается в среднем посередине, потом снова в среднем посередине, то есть средняя длина должна быть $\ell / 4$. Она работает не всегда, а только для $Y$, матожидание которых линейно относительно $X$. Пусть $E(Y \mid X = x) = g(x)$ тогда:
\begin{align*}
  E(Y) = \int_{-\infty}^{+\infty} f_X(x) E(Y \mid X = x) dx = \int_{-\infty}^{+\infty} f_X(x) g(x) dx = E(g(X)) \ne g(E(X)).
\end{align*}

\textbf{Независимые нормальные распределения}

Пусть есть $X \sim N(0, 1)$ и $Y \sim N(0, 1)$, и они независимы. Тогда

\begin{align*}
  f_{X, Y}(x, y) = f_X(x) f_Y(y) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2} \cdot \frac{1}{\sqrt{2\pi}} e^{-x^2/2} = \frac{1}{2\pi} \exp\left(-\frac{x^2 + y^2}{2}\right).
\end{align*}

То есть их совместная плотность вероятности пропорциональна $e^{-r^2/2}$, где $r$ --- расстояние до точки (0, 0). 

\begin{center}
  \begin{tikzpicture}
    \begin{axis}
      \addplot3[
        surf,
        samples=30,
        domain=-3:3,
      ]
      {gauss2d(x, 0, 1, y, 0, 1)};

    \end{axis}
  \end{tikzpicture}
\end{center}

Эквиплотные линии:

\begin{center}
  \begin{tikzpicture}
    \begin{axis}[grid=major,
                 ylabel={$Y$},
                 xlabel={$X$},
                 height=8cm,
                 width=8cm,
                 xmin=-3.5, xmax=3.5, ymin=-3.5, ymax=3.5]
      \coordinate (Center) at (axis cs:0,0);
    \end{axis}
    \draw [ultra thick, blue] (Center) circle (2.7);
    \draw [ultra thick, yellow] (Center) circle (1.8);
    \draw [ultra thick, red] (Center) circle (0.9);
\end{tikzpicture}
\end{center}

Если у нас нестандартные нормальные распределения, то бугорок может сплющиваться или растягиваться вдоль оси, и его центр будет свдигаться 

\begin{center}
  \begin{tikzpicture}
    \begin{axis}
      \addplot3[
        surf,
        samples=30,
        domain=-3:3,
      ]
      {gauss2d(x, 1, 1.5, y, -1, 0.75)};

    \end{axis}
  \end{tikzpicture}
\end{center}

Эквиплотные линии превратятся в эллипсы.

\begin{center}
  \begin{tikzpicture}
    \begin{axis}[grid=major,
                 ylabel={$Y$},
                 xlabel={$X$},
                 height=8cm,
                 width=8cm,
                 xmin=-4, xmax=6, ymin=-5, ymax=5]
      \coordinate (Center) at (axis cs:1,-1);
    \end{axis}
    \draw [ultra thick, blue] (Center) ellipse (3 and 1.5);
    \draw [ultra thick, yellow] (Center) ellipse (2 and 1);
    \draw [ultra thick, red] (Center) ellipse (1 and 0.5);
\end{tikzpicture}
\end{center}

Заметим, что оси эллипса должны быть направлены вдоль осей, иначе с.в. будут зависимые

\section{Формула Байеса для случайных величин}

Напомним смысл формулы Байеса. С помощью нее мы выражаем вероятность события, которое не можем пронаблюдать ($A_i$ в формуле) через априорные оценки веротностей другого события(ий) ($B$ в формуле), которое мы можем наблюдать, после его наблюдения.

\begin{center}
  \begin{tikzpicture}[rounded corners]
    \node (formula) [draw, rectangle, fill=blue!20, minimum height = 1.5cm, minimum width = 4.5cm] at (0,0) {
    \begin{minipage}{0.6\textwidth}
      \[
        \Pr(A_i \mid B) = \frac{\Pr(A_i) \Pr(B \mid A_i)}{\sum_j \Pr(A_j) \Pr(B \mid A_j)}
      \]
    \end{minipage}};

    \node (posterior) [text width=5cm] at (-4, -2) {Апостериорная оценка вероятности $A_i$}; 
    \node (priorA) [text width = 4cm] at (-1, 2) {Априорная оценка вероятности $A_i$}; 
    \node (priorB) [text width = 5.5cm] at (4, 2) {Априорная оценка условной вероятности наблюдаемого события $B$};
    \node (fullB) [text width = 5.5cm] at (4, -2) {Полная вероятность $B$}; 

    \draw [->, thick] (posterior) -- (formula.195);
    \draw [->, thick] (priorA) -- (formula);
    \draw [->, thick] (priorB) -- (formula.20);
    \draw [->, thick] (fullB) -- (formula);
  \end{tikzpicture}
\end{center}

Легко вывести из правила умножения и формулы полной вероятности для двух дискретных и двух непрерывных случанйых величин. Начнем с дискретных

\begin{align*}
  p_{X, Y}(x, y) &= p_Y(y) p_{X \mid Y}(x \mid y) \\
                 &= p_X(x) p_{Y \mid X}(y \mid x) \\
 \Rightarrow 
 p_{X \mid Y}(x \mid y) &= \frac{p_X(x) p_{Y \mid X}(y \mid x)}{p_Y(y)} \\
                        &= \frac{p_X(x) p_{Y \mid X}(y \mid x)}{\sum_x p_X(x) p_{Y \mid X}(y \mid x)}
\end{align*}

\begin{center}
  \begin{tikzpicture}[rounded corners]
    \node [draw, rectangle, fill=blue!20, minimum height = 1.5cm, minimum width = 4.5cm] at (0,0) {
    \begin{minipage}{0.6\textwidth}
      \[
        p_{X \mid Y}(x \mid y) = \frac{p_X(x) p_{Y \mid X}(y \mid x)}{\sum_x p_X(x) p_{Y \mid X}(y \mid x)}  
      \]
    \end{minipage}};
  \end{tikzpicture}
\end{center}

То же самое для непрерывных с.в., но говорим про плотности вероятности, а не про функцию вероятности, и суммы заменяем интегралами

\begin{align*}
  f_{X, Y}(x, y) &= f_Y(y) f_{X \mid Y}(x \mid y) \\
                 &= f_X(x) f_{Y \mid X}(y \mid x) \\
 \Rightarrow 
 f_{X \mid Y}(x \mid y) &= \frac{f_X(x) f_{Y \mid X}(y \mid x)}{f_Y(y)} \\
                        &= \frac{f_X(x) f_{Y \mid X}(y \mid x)}{\int_{\R} f_X(x) f_{Y \mid X}(y \mid x) dx}
\end{align*}

\begin{center}
  \begin{tikzpicture}[rounded corners]
    \node [draw, rectangle, fill=blue!20, minimum height = 1.5cm, minimum width = 4.5cm] at (0,0) {
    \begin{minipage}{0.6\textwidth}
      \[
        f_{X \mid Y}(x \mid y) = \frac{f_X(x) f_{Y \mid X}(y \mid x)}{\int_\R f_X(x) f_{Y \mid X}(y \mid x) dx}  
      \]
    \end{minipage}};
  \end{tikzpicture}
\end{center}

Но иногда могут быть случаи, когда есть две с.в.: одна дискретная, другая непрерывная. Можем сделать примерно следующее. Пусть $X$ --- дискретная, а $Y$ --- непрерывная

\begin{align*}
  \Pr(X = x &\cap y \le Y \le y + \delta) \\
  &= \Pr(X = x) \Pr (y \le Y \le Y + \delta \mid X = x) \approx p_X(x) f_{Y \mid X}(y \mid x) \delta \\
  &= \Pr(y \le Y \le y + \delta) \Pr(X = x \mid y \le Y \le y + \delta) \approx f_Y(y) \delta p_{X \mid Y}(x \mid y)
\end{align*}

Откуда следует, что 
\begin{align*}
  p_X(x) f_{Y \mid X}(y \mid x) = f_Y(y) p_{X \mid Y}(x \mid y)
\end{align*}

Чтобы доказать более строго, надо просто $\delta$ устремить к нулю, тогда вместо ``$\approx$'' будет ``$=$''. Получаем две формулы.

\begin{center}
  \begin{tikzpicture}[rounded corners]
    \node [draw, rectangle, fill=blue!20, minimum height = 1.5cm, minimum width = 4.5cm] at (0,0) {
    \begin{minipage}{0.4\textwidth}
      \[
        p_{X \mid Y}(x \mid y) = \frac{p_X(x) f_{Y \mid X}(y \mid x)}{f_Y(y)}  
      \]
    \end{minipage}};
  \end{tikzpicture}
  \hspace{2cm}
  \begin{tikzpicture}[rounded corners]
    \node [draw, rectangle, fill=blue!20, minimum height = 1.5cm, minimum width = 4.5cm] at (0,0) {
    \begin{minipage}{0.4\textwidth}
      \[
        f_{Y \mid X}(y \mid x) = \frac{f_Y(y) p_{X \mid Y}(x \mid y)}{p_X(x)}  
      \]
    \end{minipage}};
  \end{tikzpicture}
\end{center}

И теперь в левую формулу можно подставить формулу полной вероятности, которая работает для $f_Y(y)$:

\begin{align*}
  f_Y(y) = \sum_{x'} p_X(x') f_{Y \mid X}(y \mid x'). 
\end{align*}

С правой чуть посложнее, но пока поверьте наслово, что
\begin{align*}
  p_X(x) = \int_{\R} f_Y(y') p_{X \mid Y}(x \mid y') dy. 
\end{align*}

\textbf{Пример: наблюдаем непрерывную с.в., оцениваем дискретную}

\begin{center}
  \begin{tikzpicture}[rounded corners]
    \node [draw, rectangle, fill=blue!20, minimum height = 1.5cm, minimum width = 4.5cm] at (0,0) {
    \begin{minipage}{0.4\textwidth}
      \[
        p_{X \mid Y}(x \mid y) = \frac{p_X(x) f_{Y \mid X}(y \mid x)}{f_Y(y)}  
      \]
    \end{minipage}};
  \end{tikzpicture}
\end{center}

Ситуация: посылаем дискретный сигнал $X \in [-1, 1]$, но к нему добавляется шум $Z \sim N(0, 1)$. В итоге мы можем замерить только $Y = X + Z$. Давайте определим вероятности каждого варианта посланного сигнала, если изначально отправка каждого равновероятна.

\begin{itemize}
  \item $p_X(-1) = p_X(1) = \frac{1}{2}$
  \item $Y \sim N(0, 1) + X$, то есть если $X = 1$, то $Y\mid X = 1 \sim N(1, 1)$. Аналогично $Y \mid X = -1 \sim N(-1, 1)$
  \item Из предыдущего понимаем, что 
  \begin{itemize}
    \item $f_{Y \mid X}(y, 1) = \frac{1}{\sqrt{2\pi}} e^{-\frac{(y - 1)^2}{2}}$
    \item $f_{Y \mid X}(y, -1) = \frac{1}{\sqrt{2\pi}} e^{-\frac{(y + 1)^2}{2}}$
  \end{itemize}
  \item $f_{Y}(y) = \frac{1}{2}f_{Y \mid X}(y, 1) + \frac{1}{2} f_{Y \mid X}(y, -1)$
\end{itemize}
\begin{align*}
  p_{X \mid Y}(1 \mid y) &= \frac{\frac{1}{2} \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{(y - 1)^2}{2}}}{\frac{1}{2} \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{(y - 1)^2}{2}} + \frac{1}{2} \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{(y + 1)^2}{2}}} \\
  &= \frac{1}{1 + e^{-\frac{(y + 1)^2 - (y - 1)^2}{2}}} = \frac{1}{1 + e^{-2y}}
\end{align*}

Иллюстрация: распределение наблюдаемого значения при разных сигналов и вероятность, что посланный сигнал равне единице, в зависимости от наблюдаемого значения

\begin{center}
  \begin{tikzpicture}
    \begin{axis}[
    grid=major,
    ylabel={$f_{Y\mid X}(y \mid \cdot)$},
    xlabel={$y$},
    width = 0.8\textwidth,
    height = 5cm,
    legend pos = north east]
      \addplot[domain=-5:5, samples=61, draw=blue, ultra thick]{gauss(x, 1, 1)};
      \addlegendentry{$X = 1$};
      \addplot[domain=-5:5, samples=61, draw=red, ultra thick]{gauss(x, -1, 1)};
      \addlegendentry{$X = -1$};
    \end{axis}
  \end{tikzpicture}

  \begin{tikzpicture}
    \begin{axis}[
    grid=major,
    ylabel={$p_{X\mid Y}(1 \mid y)$},
    xlabel={$y$},
    width = 0.8\textwidth,
    height = 5cm]
    \addplot[domain=-5:5, samples=61, draw=blue, ultra thick]{1/(1 + e^(-2*x))};
    \end{axis}
  \end{tikzpicture}
\end{center}


\textbf{Пример: наблюдаем дискретную с.в., оцениваем непрерывную}

\begin{center}
  \begin{tikzpicture}[rounded corners]
    \node [draw, rectangle, fill=blue!20, minimum height = 1.5cm, minimum width = 4.5cm] at (0,0) {
    \begin{minipage}{0.4\textwidth}
      \[
        f_{Y \mid X}(y \mid x) = \frac{f_Y(y) p_{X \mid Y}(x \mid y)}{p_X(x)}  
      \]
    \end{minipage}};
  \end{tikzpicture}
\end{center}

Эксперимент: берем нечестную монету, бросаем ее и исходя из результата хотим оценить степень ее нечестности. Наблюдаемая с.в. $X \in \{0, 1\}$ и неизвестная с.в. $Y = \Pr(X = 1) \sim U(0, 1)$.

\begin{itemize}
  \item $f_Y(y) = 1$ на отрезке $[0, 1]$
  \item $p_{X \mid Y} (1 \mid y) = y$
  \item $p_{X \mid Y} (0 \mid y) = 1 - y$
  \item $p_X(1) = \int_0^1 f_Y(y') p_{X \mid Y}(1 \mid y') dy' = \int_0^1 y' dy = \frac{y^2}{2} \big|_0^1 = \frac{1}{2}$ 
\end{itemize}

\begin{align*}
  f_{Y \mid X}(y \mid 1) = \frac{1 \cdot y}{1/2} = 2y
\end{align*}

\begin{center}
  \begin{tikzpicture}
    \begin{axis}[
    grid=major,
    ylabel={$f_{Y\mid X}(y \mid \cdot)$},
    xlabel={$y$},
    width = 0.8\textwidth,
    height = 5cm,
    legend pos = north east]
      \addplot[domain=-5:5, samples=61, draw=blue, ultra thick]{gauss(x, 1, 1)};
      \addlegendentry{$X = 1$};
      \addplot[domain=-5:5, samples=61, draw=red, ultra thick]{gauss(x, -1, 1)};
      \addlegendentry{$X = -1$};
    \end{axis}
  \end{tikzpicture}

  \begin{tikzpicture}
    \begin{axis}[
    grid=major,
    ylabel={$f_{Y\mid X}(y \mid 1)$},
    xlabel={$y$},
    width = 0.6\textwidth,
    height = 6cm]
    \addplot[domain=0:1, samples=2, draw=blue, ultra thick]{2*x};
    \end{axis}
  \end{tikzpicture}
\end{center}

\section{Линейные функции от с.в.}

\textbf{Дискретные с.в.}

Если $Y = g(X)$ и мы знаем функцию вероятности $p_X(x)$, то не соствит труда посчитать 
\begin{align*}
  p_Y(y) = \sum_{x: g(x) = y} p_X(x)
\end{align*}

рассмотрим простой случай: $g(x) = ax +b$ --- линейная функция. Что происходит с функцией распределения?

\begin{center}
  \begin{tikzpicture}
    \begin{axis}[ybar, ymin=0, ymax=1,
      grid=major,
      ylabel={$p_{X}(x)$},
      xlabel={$x$}]
      \addplot
      [draw=blue, fill=blue] 
      coordinates
        {(-1, 0.3) (1,0.25) (2,0.45)};
    \end{axis}
  \end{tikzpicture}
\end{center}

Расмотрим сначала, например, $g(x) = 2x$. Легко понять, что функция вероятностей сохранила свою форму, просто столбики отъехали от оси $OY$ в два раза.
\begin{center}
  \begin{tikzpicture}
    \begin{axis}[ybar, ymin=0, ymax=1,
      grid=major,
      ylabel={$p_{2X}(x)$},
      xlabel={$x$}]
        \addplot[draw=blue, fill=blue] 
          coordinates
          {(-2, 0.3) (2,0.25) (4,0.45)};
        \coordinate (axis-left) at (axis cs:-0.2, 0.5);
        \coordinate (left) at (axis cs:-2, 0.5);
        \coordinate (axis-right) at (axis cs:0.2, 0.5);
        \coordinate (right) at (axis cs:2, 0.5);
    \end{axis}
    \draw [-{Triangle[width=18pt,length=8pt]}, red, line width=10pt] (axis-left) -- (left);
    \draw [-{Triangle[width=18pt,length=8pt]}, red, line width=10pt] (axis-right) -- (right);
  \end{tikzpicture}
\end{center}

Если мы еще прибавим константу $b = -3$, то просто сдвинем все столбики влево на $3$.

\begin{center}
  \begin{tikzpicture}
    \begin{axis}[ybar, ymin=0, ymax=1,
      grid=major,
      ylabel={$p_{2X - 3}(x)$},
      xlabel={$x$}]
      \addplot
      [draw=blue, fill=blue] 
      coordinates
        {(-5, 0.3) (-1,0.25) (1,0.45)};
      \coordinate (start) at (axis cs:0, 0.5);
      \coordinate (end) at (axis cs:-4, 0.5);
    \end{axis}
    \draw [-{Triangle[width=18pt,length=8pt]}, red, line width=10pt] (start) -- (end);
  \end{tikzpicture}
\end{center}

Очень похожая история с непрерывными. Рассмотрим пример.

\begin{center}
  \begin{tikzpicture}
   \begin{axis}[
   grid=major,
   ylabel={$f_{X}(x)$},
   xlabel={$x$},
   ymax = 0.7]
   
   \addplot[draw=blue, draw=none, fill=blue!20] coordinates
     {(-1,0.33) (0,0.33)} \closedcycle;
   \addplot[draw=blue, draw=none, fill=blue!20] coordinates
     {(0,0.66) (1,0.66)} \closedcycle;
   
   \addplot[draw=blue, ultra thick] coordinates
     {(-3,0) (-1,0)};
   \addplot[draw=blue, ultra thick] coordinates
     {(-1,0.33) (0,0.33)};
   \addplot[draw=blue, ultra thick] coordinates
     {(0,0.66) (1,0.66)};
   \addplot[draw=blue, ultra thick] coordinates
     {(1,0) (3,0)};
   \end{axis}
 \end{tikzpicture}
\end{center}

Для того, чтобы получить функцию плотности вероятности для с.в. $Y=2x$, надо растянуть ее от оси $OY$ в два раза. Заметьте, что при растягивании сама плотность упадет также в два раза.

\begin{center}
  \begin{tikzpicture}
   \begin{axis}[
   grid=major,
   ylabel={$f_{X}(x)$},
   xlabel={$x$},
   ymax = 0.7]
   
   \addplot[draw=blue, draw=none, fill=blue!20] coordinates
     {(-2,0.166) (0,0.166)} \closedcycle;
   \addplot[draw=blue, draw=none, fill=blue!20] coordinates
     {(0,0.33) (2,0.33)} \closedcycle;
   
   \addplot[draw=blue, ultra thick] coordinates
     {(-3,0) (-2,0)};
   \addplot[draw=blue, ultra thick] coordinates
     {(-2,0.166) (0,0.166)};
   \addplot[draw=blue, ultra thick] coordinates
     {(0,0.33) (2,0.33)};
   \addplot[draw=blue, ultra thick] coordinates
     {(2,0) (3,0)};
   
   \coordinate (axis-left) at (axis cs:-0.2, 0.5);
   \coordinate (left) at (axis cs:-2, 0.5);
   \coordinate (axis-right) at (axis cs:0.2, 0.5);
   \coordinate (right) at (axis cs:2, 0.5);
   \end{axis}
   \draw [-{Triangle[width=18pt,length=8pt]}, red, line width=10pt] (axis-left) -- (left);
   \draw [-{Triangle[width=18pt,length=8pt]}, red, line width=10pt] (axis-right) -- (right);
 \end{tikzpicture}
\end{center}

Ну и сдвиг при добавлении константы аналогичный. Рассмотрим, например, $g(x) = 2x - 3$

\begin{center}
  \begin{tikzpicture}
   \begin{axis}[
   grid=major,
   ylabel={$f_{X}(x)$},
   xlabel={$x$},
   ymax = 0.7]
   
      \addplot[draw=blue, draw=none, fill=blue!20] coordinates
        {(-5,0.166) (-3,0.166)} \closedcycle;
      \addplot[draw=blue, draw=none, fill=blue!20] coordinates
        {(-3,0.33) (-1,0.33)} \closedcycle;

      \addplot[draw=blue, ultra thick] coordinates
        {(-6,0) (-5,0)};
      \addplot[draw=blue, ultra thick] coordinates
        {(-5,0.166) (-3,0.166)};
      \addplot[draw=blue, ultra thick] coordinates
        {(-3,0.33) (-1,0.33)};
      \addplot[draw=blue, ultra thick] coordinates
        {(-1,0) (0,0)};
   
      \coordinate (start) at (axis cs:0, 0.5);
      \coordinate (end) at (axis cs:-3, 0.5);
   \end{axis}
   \draw [-{Triangle[width=18pt,length=8pt]}, red, line width=10pt] (start) -- (end);
 \end{tikzpicture}
\end{center}

Как это в общем случае делать с.в.? Рассмотрим $Y = aX + b$ (где $a \ne 0$, иначе это скучный случай, когда $Y = b$ с вероятностью 1). Пусть сначала $X$ дискретная, и нам известна ее функция вероятностей. Тогда

\begin{align*}
  p_Y(y) = \Pr(Y = y) = \Pr(aX + b = y) = \Pr\left(X = \frac{y - b}{a}\right) = p_X\left( \frac{y - b}{a}\right)
\end{align*}

С непрерывными такое не работает, так как вероятность, что непрерывная с.в. равна конкретному числу, есть ноль. Но мы можем работать с функциями распределения! Допустим мы знаем $f_X(x)$ и $F_X(x)$. Рассмотрим случай $a > 0$

\begin{align*}
  F_Y(y) &= \Pr(Y \le y) = \Pr(aX + b \le y) = \Pr\left(X \le \frac{y - b}{a}\right) = F_X\left(\frac{y - b}{a}\right), \\
  f_Y(y) &= F_Y'(y) = f_X\left(\frac{y - b}{a}\right) \cdot \frac{1}{a}.
\end{align*}

И отдельно $a < 0$
\begin{align*}
  F_Y(y) &= \Pr(Y \le y) = \Pr(aX + b \le y) = \Pr\left(X \ge \frac{y - b}{a}\right) = 1 - F_X\left(\frac{y - b}{a}\right), \\
  f_Y(y) &= F_Y'(y) = -f_X\left(\frac{y - b}{a}\right) \cdot \frac{1}{a}.
\end{align*}

Объединяя два случая, получаем:

\begin{align*}
  f_Y(y) = \frac{1}{|a|}f_X\left(\frac{y - b}{a}\right).
\end{align*}

Докажем теперь, что линейное преобразование нормального распределения оставляет его нормальным. Пусть $X \sim N(\mu, \sigma^2)$ и $Y = aX + b$. Значит,

\begin{align*}
  f_Y(y) &= \frac{1}{|a|}f_X\left(\frac{y - b}{a}\right) \\
         &= \frac{1}{|a|\sigma \sqrt{2\pi}} \exp\left(\frac{\left(\frac{y - b}{a} - \mu\right)^2}{2\sigma^2}\right) \\
         &= \frac{1}{(|a|\sigma) \sqrt{2\pi}} \exp\left(\frac{\left(y - (b + a\mu)\right)^2}{2(a\sigma)^2}\right),
\end{align*}
что есть функция плотности вероятности для $N(a\mu + b, (a\sigma)^2)$.





\end{document}