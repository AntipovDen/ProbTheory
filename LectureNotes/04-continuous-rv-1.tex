\documentclass[12pt]{article}

\usepackage{a4wide}

\usepackage[utf8]{inputenc} 
\usepackage[russian]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{pgfplots}
\usepgfplotslibrary{statistics}
\usetikzlibrary{decorations.pathreplacing,calc,tikzmark, patterns,arrows.meta}
\pgfmathdeclarefunction{gauss}{3}{%
  \pgfmathparse{1/(#3*sqrt(2*pi))*exp(-((#1-#2)^2)/(2*#3^2))}%
}

\usepackage{xspace}

\usepackage{mathtools}
\usepackage{cite}
\usepackage{array}
\usepackage{multirow}
\usepackage{tabularx}

\newcommand\N{\mathbb{N}}
\newcommand\R{\mathbb{R}}
\newcommand\eps{\varepsilon}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Geom}{Geom}
\DeclareMathOperator{\pow}{pow}
\DeclareMathOperator{\Bern}{Bern}
\DeclareMathOperator{\Exp}{Exp}
\DeclareMathOperator{\Var}{Var}


\title{Лекция 3. Непрерывные с.в., часть 1}

\begin{document}
\maketitle


  \section{Непрерывные случайные величины}

  \textbf{Определение непрерывных с.в.}

  В случае с дискретными величинами:

  \begin{center}
    \begin{tikzpicture}
        \begin{axis}[ybar, ymin=0,
        grid=major,
        ylabel={$p_{X}(x)$},
        xlabel={$x$}]
        \addplot
        [draw=blue, fill=blue] 
        coordinates
            {(1, 0.1) (2, 0.2) (3,0.2) (4,0.1) (5,0.3) (6,0.1)};
        \end{axis}
        \node (a) [red] at (2.3, 0) {\textbf{\huge{[}}};
        \node (b) [red] at (5.7, 0) {\textbf{\huge{]}}};
        \node [below=1em, red] at (a) {\textbf{a}};
        \node [below=1em, red] at (b) {\textbf{b}};

        \draw [red, ultra thick] (2.3, 0) -- (5.7, 0);
    \end{tikzpicture}
  \end{center}

  \begin{align*}
      \Pr[a \le X \le b] = \sum_{x: a \le x \le b} p_X(x)
  \end{align*}

  Но если $X$ может принимать любые вещественные значения из этого интервала? Тогда нам нужна функция, которая показывает, сколько вероятностной массы лежит на каждом элементарном отрезке.

  \begin{center}
    \begin{tikzpicture}
        \begin{axis}[ybar, ymin=0, ymax=0.3, xmin=-0.1, xmax=5.1,
        grid=major,
        ylabel={$f_{X}(x)$},
        xlabel={$x$}]
        \end{axis}
        \fill [blue!20] (2, 3) to[out=0,in=180] (4, 1) to[out=0,in=180] (6, 4) -- (6, 0) -- (2, 0);

        \draw [thick] (0, 1) to[out=45,in=180] (2, 3)
                     to[out=0,in=180] (4, 1)
                     to[out=0,in=180] (6, 4)
                     to[out=0, in=150] (6.9, 3);

        \node (a) [red] at (2, 0) {\textbf{\huge{[}}};
        \node (b) [red] at (6, 0) {\textbf{\huge{]}}};
        \node [below=1em, red] at (a) {\textbf{a}};
        \node [below=1em, red] at (b) {\textbf{b}};

        \draw [red, ultra thick] (2, 0) -- (6, 0);
    \end{tikzpicture}
  \end{center}

  \begin{align}\label{eq:def-contnuous}
      \Pr[a \le X \le b] = \int_a^b f_X(x) dx 
  \end{align}

  \emph{Определение:} Случайная величина называется непрерывной, если для нее существует такая функция $f_X(x)$, что для любых $a, b \in \R$ (где $a \le b$) верно~\eqref{eq:def-contnuous}.


  $f_X(x)$ --- \emph{плотность вероятности} с.в. $X$:

  \begin{align*}
      \Pr(a \le X \le a + \eps) \approx f_X(a) \cdot \varepsilon 
  \end{align*}

  Плотность вероятности --- аналог функции вероятностей для непрерывных с.в.:

  \begin{itemize}
      \item $p_X(x) \ge 0$
      \item $\sum_x p_X(x) = 1$
  \end{itemize}

  То же самое
  \begin{itemize}
      \item $f_X(x) \ge 0$
      \item $\int_{-\infty}^{+\infty} p_X(x) = 1$
  \end{itemize}

  \emph{NB}:
  
  \begin{align*}
      \Pr(X = a) = \Pr(a \le X \le a) = \int_a^a f_X(x) dx = 0
  \end{align*}

  Поэтому:
  \begin{align*}
      \Pr(a \le X \le b) = \Pr(X = a) + \Pr(X = b) + \Pr(a < X < b) = \Pr(a < X < b) 
  \end{align*}

  \emph{NB}: Мы ушли от понятия событий, но у нас по-прежнему есть какая-то $\Omega$, на которой и задана с.в. $X$. Просто нам сейчас проще быть чисто в терминах с.в.


  \emph{NB}: Переопредилим дискретные с.в. как с.в., для которых есть функция вероятностей, то есть число возможныъх значений которых счетно.

  \emph{NB}: Вы уже могли догадаться, что с.в. могут быть и смешанные, но про это позже.

  
  Пример: равномерное распределение

  \begin{center}
    \begin{tikzpicture}
        \begin{axis}[ybar, ymin=0, ymax=0.3,
        grid=major,
        ylabel={$p_{X}(x)$},
        xlabel={$x$}]
        \addplot
        [draw=blue, fill=blue] 
        coordinates
            {(1, 0.2) (2, 0.2) (3,0.2) (4,0.2) (5,0.2)};
        \end{axis}
    \end{tikzpicture}
  \end{center}

  \begin{center}
    \begin{tikzpicture}
        \begin{axis}[ybar, ymin=0, ymax=0.3, xmin=0, xmax=6,
        grid=major,
        ylabel={$f_{X}(x)$},
        xlabel={$x$}]
        \end{axis}
        \fill [blue!20] (1.15, 3.8) -- (5.7, 3.8) -- (5.7, 0) -- (1.15, 0);

        \draw [ultra thick] (0, 0) -- (1.15, 0);
        \draw [ultra thick] (1.15, 3.8) -- (5.7, 3.8);
        \draw [ultra thick] (5.7, 0) -- (6.85, 0);
        

    \end{tikzpicture}
  \end{center}

  Обобщение: частично равномерное распределение


  \begin{center}
    \begin{tikzpicture}
        \begin{axis}[ybar, ymin=0, ymax=0.4, xmin=0, xmax=6,
        grid=major,
        ylabel={$f_{X}(x)$},
        xlabel={$x$}]
        \end{axis}
        \fill [blue!20] (1.15, 2.8) -- (3.45, 2.8) -- (3.45, 1.4) -- (4.6, 1.4) -- (4.6, 4.2) -- (5.7, 4.2) -- (5.7, 0) -- (1.15, 0);
         

        \draw [ultra thick] (0, 0) -- (1.15, 0);
        \draw [ultra thick] (1.15, 2.8) -- (3.45, 2.8);
        \draw [ultra thick] (3.45, 1.4) -- (4.6, 1.4);
        \draw [ultra thick] (4.6, 4.2) -- (5.7, 4.2);
        \draw [ultra thick] (5.7, 0) -- (6.85, 0);
        

    \end{tikzpicture}
  \end{center}

  \section{Матожидание}

  Для дискретных величин:
  \begin{align*}
      E(X) = \sum_x x p_X(x)
  \end{align*}

  Для непрерывных: заменяем сумму на интеграл, а функцию вероятностей на плотность вероятности
  \begin{align*}
      E(X) = \int_{-\infty}^{+\infty} x f_X(x) dx
  \end{align*}

  Важно: интеграл должен сходиться абсолютно

  \emph{Интерпретация:} центр масс вероятностной массы

  \textbf{Свойства матожидания}

  \begin{itemize}
    \item $X \ge 0 \Rightarrow E[X] > 0$
    \item $X \in [a, b] \Rightarrow E[X] \in [a, b]$
    \item Матожидание функции от с.в.:
    \begin{align*}
        E(g(X)) = \int_{-\infty}^{+\infty} g(x) f_X(x) dx
    \end{align*}
    \item Пример
    \begin{align*}
        E(X^2) = \int_{-\infty}^{+\infty} x^2 f_X(x) dx
    \end{align*}
    \item Линейность: $E(aX + b) = aE(X) + b$
  \end{itemize}

  \section{Дисперсия}

  Как и для дискретных:
  \begin{align*}
      \Var(X) = E((X - \mu)^2) = \int_{-\infty}^{+\infty} (x - \mu)^2 f_X(x) dx
  \end{align*}

  среднеквадратичное отклонение:
  \begin{align*}
      \sigma_X = \sqrt{\Var(X)}
  \end{align*}

  Свойства --- те же:
  \begin{itemize}
      \item $\Var(aX + b) = a^2\Var(X)$
      \item $\Var(X) = E(X^2) - (E(X))^2$
  \end{itemize}

  \section{Моменты стандартных распределений}

  {NB:} $i$-й момент распределения --- $\int_{-\infty}^{+\infty} x^i f_X(x) dx$ (для дискретных с.в --- сумма)

  \textbf{Равномерное распределение}

  $X \sim U(a, b)$ 

  Матожидание:
  \begin{align*}
    E[X] = \int_{-\infty}^{+\infty} x f_X(x) dx = \int_{a}^{b} x \frac{1}{b - a} dx = \frac{a + b}{2}. 
  \end{align*}

  Дисперсия:
  \begin{align*}
    E[X^2] &= \int_{-\infty}^{+\infty} x^2 f_X(x) dx = \int_{a}^{b} x^2 \frac{1}{b - a} dx \\
           &= \frac{b^3 - a^3}{3(b - a)} = \frac{b^2 + ab + a^2}{3}\\
    \Var(X) &= E[X^2] - (E[X])^2 = \frac{4b^2 + 4ab + 4a^2 - 3b^2 - 6ab - 3a^2}{12} = \frac{(b - a)^2}{12}. 
  \end{align*}

  \textbf{Экспоненциальное распределение}

  Говорим, что $X$ следует экспоненциальному распределению $\Exp(\lambda)$ с параметром $\lambda$, если

  \begin{align*}
    f_X(x) = \begin{cases}
      \lambda e^{-\lambda x}, &x \ge 0 \\
      0, &x < 0
    \end{cases}
  \end{align*}

  \emph{NB}: Это аналог геометрического распределения с параметром $p = \lambda$.

  Матожидание:
  \begin{align*}
    E[X] &= \int_0^{+\infty} x \lambda e^{-\lambda x} dx = - \int_0^{+\infty} x d e^{-\lambda x} = - x e^{-\lambda x} \bigg|_0^{+\infty} + \int_0^{+\infty} e^{-\lambda x} dx \\
    &= 0 - \frac{1}{\lambda} \bigg|_0^{+\infty} = \frac{1}{\lambda}.
  \end{align*}

  Дисперсия (два раза интегрируем по частям):
  \begin{align*}
    E[X] &= \int_0^{+\infty} x^2 \lambda e^{-\lambda x} dx = \frac{2}{\lambda}.
    \Var(X) &= \frac{2}{\lambda^2} - \frac{1}{\lambda^2} = \frac{1}{\lambda^2}.
  \end{align*}

  Довольно хорошо сконцентрирована, так как вероятность хвоста экспоненциально падает:
  \begin{align*}
    \Pr(X \ge a) = \int_a^{+\infty} \lambda e^{-\lambda x} dx = e^{-\lambda a}.
  \end{align*}


  \section{Функция распределения}

  $F_X(x) = \Pr(X \le x)$ --- \emph{функция распределения} с.в. $X$ (как дискретной, так и непрерывной).


  Как считать:

  \begin{align*}
    F_X(x) = \int_{-\infty}^x f_X(t) dt
  \end{align*}

  Легко заметить: $F_X'(x) = f_X(x)$

  Пример: равномерное распределение.

  \begin{center}
    \begin{tikzpicture}
        \begin{axis}[ymin=-0.1, ymax=1, xmin=0, xmax=5,
        width = 0.45\textwidth,
        grid=major,
        ylabel={$f_{X}(x)$},
        xlabel={$x$},
        ultra thick]
        \addplot[draw=blue,fill=blue!30!white] coordinates
          {(0,0) (1,0)};
          \addplot[draw=none, fill=blue!30!white] coordinates
          {(1,0.33) (4,0.33)} \closedcycle;
        \addplot[draw=blue] coordinates
          {(1,0.33) (4,0.33)};
        \addplot[draw=blue,fill=blue!30!white] coordinates
          {(4,0) (5,0)};
        \end{axis}
    \end{tikzpicture}
    \begin{tikzpicture}
      \begin{axis}[ymin=-0.1, ymax=1.1, xmin=0, xmax=5,
      width = 0.45\textwidth,
      grid=major,
      ylabel={$F_{X}(x)$},
      xlabel={$x$},
      ultra thick]
      \addplot[draw=blue] coordinates
        {(0,0) (1,0) (4, 1) (5, 1)};
      \end{axis}
  \end{tikzpicture}
  \end{center}

   Функцию распределения можно считать и для дискретной случайной величины:

   \begin{center}
    \begin{tikzpicture}
        \begin{axis}[ybar, ymin=0, ymax=1,
        width = 0.45\textwidth,
        grid=major,
        ylabel={$p_{X}(x)$},
        xlabel={$x$}]
        \addplot
        [draw=blue, fill=blue] 
        coordinates
            {(1, 0.25) (3, 0.5) (4,0.25)};
        \end{axis}
    \end{tikzpicture}
    \begin{tikzpicture}
      \begin{axis}[ymin=-0.1, ymax=1.1, xmin=0, xmax=5,
      width = 0.45\textwidth,
      grid=major,
      ylabel={$F_{X}(x)$},
      xlabel={$x$},
      ultra thick]
      \addplot[draw=blue] coordinates
        {(0,0) (1,0)};
      \addplot[draw=blue] coordinates
        {(1,0.25) (3,0.25)};
      \addplot[draw=blue] coordinates
        {(3, 0.75) (4, 0.75)};
      \addplot[draw=blue] coordinates
        {(4, 1) (5, 1)};
      \addplot[only marks, draw=blue] coordinates
        {(1,0.25) (3, 0.75) (4, 1)};
      \end{axis}
  \end{tikzpicture}
  \end{center}

  Свойства функции распределения:
  \begin{itemize}
    \item Неубывающая
    \item $\lim_{x \to + \infty} F_X(x) = 1$
    \item $\lim_{x \to - \infty} F_X(x) = 0$
  \end{itemize}

  \section{Нормальное распределение (распределение Гаусса)}

  Очень важная штука:
  \begin{itemize}
    \item Важна в центральной предельной теореме
    \item Часто на практике неизвестные распределения приближаются нормальным
  \end{itemize}

  \emph{Стандартное нормальное:} $X \sim N(0, 1) \leftrightarrow f_X(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}$

  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[
      grid=major,
      ylabel={$f_{X}(x)$},
      xlabel={$x$}]
      \addplot[domain=-3:3, samples=61, draw=blue, ultra thick]{gauss(x, 0, 1)};
      \addplot[domain=-3:3, samples=61, draw=none, fill=blue!20]{gauss(x, 0, 1)} \closedcycle;
      \end{axis}
  \end{tikzpicture}
  \end{center}

  Откуда берется коэффициент нормализации $\frac{1}{\sqrt{2\pi}}$? Из интеграла Гаусса
  \begin{align*}
    \int_{-\infty}^{+\infty} e^{-x^2} dx = \sqrt{\pi}
  \end{align*}

  Свойства $N(0, 1)$:

  \begin{align*}
    E[X] = \int_{-\infty}^{+\infty} x \frac{1}{\sqrt{2\pi}}e^{-x^2/2} dx = 0,
  \end{align*}
  так как это интеграл нечетной функции, которая в бесконечности очень маленькая.

  \begin{align*}
    \Var(X) &= E[X^2] = \int_{-\infty}^{+\infty} x^2 \frac{1}{\sqrt{2\pi}}e^{-x^2/2} dx = \int_{-\infty}^{+\infty} x \frac{1}{\sqrt{2\pi}}e^{-x^2/2}d\frac{x^2}{2} \\
            &= - \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} x \frac{1}{\sqrt{2\pi}}e^{-x^2/2}de^{-x^2/2} \\
            &= - \frac{1}{\sqrt{2\pi}} x e^{-x^2/2} \bigg|_{-\infty}^{+\infty} + \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} e^{-x^2/2} dx \\
            &= 0 + \frac{\sqrt{2\pi}}{\sqrt{2\pi}} = 1.
  \end{align*}

  В записи $N(0, 1)$ нолик как раз обозначает матожидание, а единица --- дисперсию

  Обобщенное нормальное распределение: $X \sim N(\mu, \sigma^2) \Leftrightarrow f_X(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{(x - \mu)^2}{2\sigma^2}}$

  \begin{itemize}
    \item $\mu$ --- новое матожидание, насколько мы сдвигаем ось симметрии $X$.
    \item $\sigma$ --- новая дисперсия, насколько мы растягиваем распределение от оси симметрии.
  \end{itemize}

  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[
      grid=major,
      ylabel={$f_{X}(x)$},
      xlabel={$x$},
      legend pos=outer north east]
      \addplot[domain=-3:5, samples=81, draw=blue, thick]{gauss(x, 0, 1)};
      \addlegendentry{$\mu = 0, \sigma = 1$}
      \addplot[domain=-3:5, samples=81, draw=red, thick]{gauss(x, 2, 1)};
      \addlegendentry{$\mu = 2, \sigma = 1$}

      \addplot[domain=-3:5, samples=81, draw=none, fill=blue, fill opacity=0.2]{gauss(x, 0, 1)} \closedcycle;
      \addplot[domain=-3:5, samples=81, draw=none, fill=red, fill opacity=0.2]{gauss(x, 2, 1)} \closedcycle;
      \end{axis}
  \end{tikzpicture}
  \end{center}
  
  Чем меньше $\sigma$ (срежнеквадратичное отклонение), тем больше распределение сжато вокруг оси симметрии
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[
      grid=major,
      ylabel={$f_{X}(x)$},
      xlabel={$x$},
      legend pos=outer north east]
      \addplot[domain=-3:3, samples=81, draw=blue, thick]{gauss(x, 0, 1)};
      \addlegendentry{$\mu = 0, \sigma = 1$}
      \addplot[domain=-3:3, samples=81, draw=red, thick]{gauss(x, 0, 2)};
      \addlegendentry{$\mu = 0, \sigma = 4$}
      \addplot[domain=-3:3, samples=81, draw=green!40!black, thick]{gauss(x, 0, 0.5)};
      \addlegendentry{$\mu = 0, \sigma = 0.25$}

      % \addplot[domain=-3:5, samples=81, draw=none, fill=blue, fill opacity=0.2]{gauss(x, 0, 1)} \closedcycle;
      % \addplot[domain=-3:5, samples=81, draw=none, fill=red, fill opacity=0.2]{gauss(x, 2, 1)} \closedcycle;
      \end{axis}
  \end{tikzpicture}
  \end{center}

  Полезное свойство нормальной случайной величины: если $X\sim N(\mu, \sigma^2)$ и при этом $Y = aX + b$, то $Y$ тоже имеет нормальное распределение. Это мы докажем позже, но пока давайте посмотрим, какому именно распределению.

  \begin{itemize}
    \item $E(Y)$ должно равняться $E(aX + b) = aE(X) + b = a\mu + b$
    \item $\Var(Y)$ должна равняться $\Var(aX + b) = a^2\Var(X) = a^2 \sigma^2$
  \end{itemize}
  Значит, $Y \sim N(a\mu + b, a^2\sigma^2)$.

  Функция распределения $X \sim N(0, 1)$ обозначается буквой $\Phi$:
  \begin{align*}
    \Phi(x) = F_X(x) = \int_{-\infty}^x \frac{1}{\sqrt{2\pi}}e^{-\frac{t^2}{2}} dt
  \end{align*}
  Так как интеграл неберущийся, ее значения считаются с помощью таблиц.

\begin{center}
  \begin{table}
    \caption{Таблица для вычисления функции распределения стандартного нормального распределения $N(0, 1)$. В $i$-й строке и $j$-ом столбце число равно $\int_0^{0.1i+ 0.01j} f_X(x) dx $}
    \begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|}
      \hline
      & 0.00 & 0.01 & 0.02 & 0.03 & 0.04 & 0.05 & 0.06 & 0.07 & 0.08 & 0.09 \\ \hline\hline
      0.0 & 0.0000 & 0.0040 & 0.0080 & 0.0120 & 0.0160 & 0.0199 & 0.0239 & 0.0279 & 0.0319 & 0.0359 \\ \hline
      0.1 & 0.0398 & 0.0438 & 0.0478 & 0.0517 & 0.0557 & 0.0596 & 0.0636 & 0.0675 & 0.0714 & 0.0753 \\ \hline
      0.2 & 0.0793 & 0.0832 & 0.0871 & 0.0910 & 0.0948 & 0.0987 & 0.1026 & 0.1064 & 0.1103 & 0.1141 \\ \hline
      0.3 & 0.1179 & 0.1217 & 0.1255 & 0.1293 & 0.1331 & 0.1368 & 0.1406 & 0.1443 & 0.1480 & 0.1517 \\ \hline
      0.4 & 0.1554 & 0.1591 & 0.1628 & 0.1664 & 0.1700 & 0.1736 & 0.1772 & 0.1808 & 0.1844 & 0.1879 \\ \hline
      0.5 & 0.1915 & 0.1950 & 0.1985 & 0.2019 & 0.2054 & 0.2088 & 0.2123 & 0.2157 & 0.2190 & 0.2224 \\ \hline
      0.6 & 0.2257 & 0.2291 & 0.2324 & 0.2357 & 0.2389 & 0.2422 & 0.2454 & 0.2486 & 0.2517 & 0.2549 \\ \hline
      0.7 & 0.2580 & 0.2611 & 0.2642 & 0.2673 & 0.2704 & 0.2734 & 0.2764 & 0.2794 & 0.2823 & 0.2852 \\ \hline
      0.8 & 0.2881 & 0.2910 & 0.2939 & 0.2967 & 0.2995 & 0.3023 & 0.3051 & 0.3078 & 0.3106 & 0.3133 \\ \hline
      0.9 & 0.3159 & 0.3186 & 0.3212 & 0.3238 & 0.3264 & 0.3289 & 0.3315 & 0.3340 & 0.3365 & 0.3389 \\ \hline
      1.0 & 0.3413 & 0.3438 & 0.3461 & 0.3485 & 0.3508 & 0.3531 & 0.3554 & 0.3577 & 0.3599 & 0.3621 \\ \hline
      1.1 & 0.3643 & 0.3665 & 0.3686 & 0.3708 & 0.3729 & 0.3749 & 0.3770 & 0.3790 & 0.3810 & 0.3830 \\ \hline
      1.2 & 0.3849 & 0.3869 & 0.3888 & 0.3907 & 0.3925 & 0.3944 & 0.3962 & 0.3980 & 0.3997 & 0.4015 \\ \hline
      1.3 & 0.4032 & 0.4049 & 0.4066 & 0.4082 & 0.4099 & 0.4115 & 0.4131 & 0.4147 & 0.4162 & 0.4177 \\ \hline
      1.4 & 0.4192 & 0.4207 & 0.4222 & 0.4236 & 0.4251 & 0.4265 & 0.4279 & 0.4292 & 0.4306 & 0.4319 \\ \hline
      1.5 & 0.4332 & 0.4345 & 0.4357 & 0.4370 & 0.4382 & 0.4394 & 0.4406 & 0.4418 & 0.4429 & 0.4441 \\ \hline
      1.6 & 0.4452 & 0.4463 & 0.4474 & 0.4484 & 0.4495 & 0.4505 & 0.4515 & 0.4525 & 0.4535 & 0.4545 \\ \hline
      1.7 & 0.4554 & 0.4564 & 0.4573 & 0.4582 & 0.4591 & 0.4599 & 0.4608 & 0.4616 & 0.4625 & 0.4633 \\ \hline
      1.8 & 0.4641 & 0.4649 & 0.4656 & 0.4664 & 0.4671 & 0.4678 & 0.4686 & 0.4693 & 0.4699 & 0.4706 \\ \hline
      1.9 & 0.4713 & 0.4719 & 0.4726 & 0.4732 & 0.4738 & 0.4744 & 0.4750 & 0.4756 & 0.4761 & 0.4767 \\ \hline
      2.0 & 0.4772 & 0.4778 & 0.4783 & 0.4788 & 0.4793 & 0.4798 & 0.4803 & 0.4808 & 0.4812 & 0.4817 \\ \hline
      2.1 & 0.4821 & 0.4826 & 0.4830 & 0.4834 & 0.4838 & 0.4842 & 0.4846 & 0.4850 & 0.4854 & 0.4857 \\ \hline
      2.2 & 0.4861 & 0.4864 & 0.4868 & 0.4871 & 0.4875 & 0.4878 & 0.4881 & 0.4884 & 0.4887 & 0.4890 \\ \hline
      2.3 & 0.4893 & 0.4896 & 0.4898 & 0.4901 & 0.4904 & 0.4906 & 0.4909 & 0.4911 & 0.4913 & 0.4916 \\ \hline
      2.4 & 0.4918 & 0.4920 & 0.4922 & 0.4925 & 0.4927 & 0.4929 & 0.4931 & 0.4932 & 0.4934 & 0.4936 \\ \hline
      2.5 & 0.4938 & 0.4940 & 0.4941 & 0.4943 & 0.4945 & 0.4946 & 0.4948 & 0.4949 & 0.4951 & 0.4952 \\ \hline
      2.6 & 0.4953 & 0.4955 & 0.4956 & 0.4957 & 0.4959 & 0.4960 & 0.4961 & 0.4962 & 0.4963 & 0.4964 \\ \hline
      2.7 & 0.4965 & 0.4966 & 0.4967 & 0.4968 & 0.4969 & 0.4970 & 0.4971 & 0.4972 & 0.4973 & 0.4974 \\ \hline
      2.8 & 0.4974 & 0.4975 & 0.4976 & 0.4977 & 0.4977 & 0.4978 & 0.4979 & 0.4979 & 0.4980 & 0.4981 \\ \hline
      2.9 & 0.4981 & 0.4982 & 0.4982 & 0.4983 & 0.4984 & 0.4984 & 0.4985 & 0.4985 & 0.4986 & 0.4986 \\ \hline
      3.0 & 0.4987 & 0.4987 & 0.4987 & 0.4988 & 0.4988 & 0.4989 & 0.4989 & 0.4989 & 0.4990 & 0.4990 \\ \hline
      
    \end{tabular}
  \end{table}
\end{center}

Как работать с такими таблицами. Пусть мы хотим посчитать вероятность того, что $X \sim N(0, 1)$ не больше, чем $2.39$. Находим строчку $2.3$, столбец $0.09$, смотрим на число в их пересечении, добавляем к нему $0.5$. Если хотим посчитать $\Pr(X \le -2.39)$, то вычитаем это число из $0.5$. 

Как пользоваться таблицей, если $X \sim N(\mu, \sigma^2)$? И пусть мы хотим найти вероятность $\Pr(X \in [a, b])$.
Для этого Давайте рассмотрим $Y = \frac{X - \mu}{\sigma}$. Заметим, что $Y \sim N(0, 1)$. Теперь запишем интересующее нас событие следующим образом

\begin{align*}
  a &\le X &\le b \\
  a - \mu &\le X - \mu &\le b - \mu  \\
  \frac{a - \mu}{\sigma} & \le \frac{X - \mu}{\sigma} &\le \frac{b - \mu}{\sigma} 
\end{align*}

То есть искомая вероятность равна $\Pr(Y \in [\frac{a - \mu}{\sigma}, \frac{b - \mu}{\sigma}])$, а это уже вычисляется по таблице.


\section{Условная плотность вероятности}

Напомним трактовку плотность вероятности. Это то, сколько вероятностной массы приходится на маленький интервал значений с.в.:

\[f_X(x) \delta \approx \Pr(X \in [x, x + \delta])\]

Но вероятностная мера может меняться при условии, что произошло событие $A$. В этом случае определяем

\[f_{X\mid A} (x) \delta \approx \Pr(X \in [x, x + \delta] \mid A)\]

Точное определение: плотность вероятности с.в. $X$ при условии $A$ есть такая функция $f_{X \mid A}(x)$, что для любого измеримого множества $B$ верно, что
\begin{align*}
  \Pr(X \in B \mid A) = \int_B f_{X \mid A}(x) dx.
\end{align*}

\emph{NB:} у нас опять просто поменялась вероятностная мера. То есть у условной плотности вероятности будут все те же свойства:
\begin{itemize}
  \item $f_{X \mid A}(x) \ge 0$
  \item $\int_{-\infty}^{+\infty} f_{X \mid A} (x) dx = 1$
 \end{itemize}

 Вычисляем аналогично условной функции вероятности. Пусть $x \in A$, тогда

 \begin{align*}
  f_{X\mid A} (x) \delta &\approx \Pr(X \in [x, x + \delta] \mid A) = \frac{\Pr(X \in [x, x + \delta] \cap X \in A)}{\Pr(A)} \\
  &= \frac{\Pr(X \in [x, x + \delta])}{\Pr(A)} \approx \frac{f_X(x) \delta}{\Pr(A)}
 \end{align*}

 Поэтому строго говоря, она вычисляется так:
 \begin{align*}
   f_{X\mid A}(x) = \begin{cases}
     \frac{f_X(x)}{\Pr(A)}, &\text{ если } x \in A, \\
     0, &\text{ иначе.}
   \end{cases}
 \end{align*}
 То есть масштабируем плотность вероятности по событию $A$.

 \section{Условное матожидание}

 Условное матожидание определяем аналогично:

 \begin{align*}
   E(X \mid A) = \int_{-\infty}^{+\infty} x f_{X \mid A}(x) dx
 \end{align*}

 Работает то же самое правило и для функций от с.в. (у нас просто новая плотность вероятности при условии $A$):
 \begin{align*}
   E(g(X) \mid A) = \int_{-\infty}^{+\infty} g(x) f_{X \mid A}(x) dx
 \end{align*}

 \section{Пример условных с.в.}

 Рассмотрим частично равномерное распределение:
 \begin{align*}
   f_X(x)  =\begin{cases}
     0.25, x \in [0, 2) \\
     0.15, x \in [2, 3) \\
     0.35, x \in [3, 4] \\
     0, \text{ иначе.}
   \end{cases}
 \end{align*}


\begin{center}
   \begin{tikzpicture}
    \begin{axis}[
    grid=major,
    ylabel={$f_{X}(x)$},
    xlabel={$x$}]
    
    \addplot[draw=blue, draw=none, fill=blue!20] coordinates
      {(0,0.25) (2,0.25)} \closedcycle;
    \addplot[draw=blue, draw=none, fill=blue!20] coordinates
      {(2,0.15) (3,0.15)} \closedcycle;
    \addplot[draw=blue, draw=none, fill=blue!20] coordinates
      {(3,0.35) (4,0.35)} \closedcycle;
    
    \addplot[draw=blue, ultra thick] coordinates
      {(-1,0) (0,0)};
    \addplot[draw=blue, ultra thick] coordinates
      {(0,0.25) (2,0.25)};
    \addplot[draw=blue, ultra thick] coordinates
      {(2,0.15) (3,0.15)};
    \addplot[draw=blue, ultra thick] coordinates
      {(3,0.35) (4,0.35)};
    \addplot[draw=blue, ultra thick] coordinates
      {(4,0) (5,0)};
    \end{axis}
  \end{tikzpicture}
\end{center}

Пусть $A = [1, 3]$. Тогда $\Pr(A) = 0.25 \cdot 1 + 0.15 \cdot 1 = 0.4$ 

\begin{center}
  \begin{tikzpicture}
   \begin{axis}[
   grid=major,
   ylabel={$f_{X}(x)$},
   xlabel={$x$}]
   
   \addplot[draw=blue, draw=none, fill=blue!20] coordinates
     {(0,0.25) (1,0.25)} \closedcycle;
    \addplot[draw=blue, draw=none, fill=red!20] coordinates
     {(1,0.25) (2,0.25)} \closedcycle;
   \addplot[draw=blue, draw=none, fill=red!20] coordinates
     {(2,0.15) (3,0.15)} \closedcycle;
   \addplot[draw=blue, draw=none, fill=blue!20] coordinates
     {(3,0.35) (4,0.35)} \closedcycle;
   
   \addplot[draw=blue, ultra thick] coordinates
     {(-1,0) (0,0)};
    \addplot[draw=blue, ultra thick] coordinates
      {(0,0.25) (1,0.25)};
    \addplot[draw=red, ultra thick] coordinates
      {(1,0.25) (2,0.25)};
   \addplot[draw=red, ultra thick] coordinates
     {(2,0.15) (3,0.15)};
   \addplot[draw=blue, ultra thick] coordinates
     {(3,0.35) (4,0.35)};
   \addplot[draw=blue, ultra thick] coordinates
     {(4,0) (5,0)};
   \node [red] at (axis cs:2,0.1) {$A$};
  \end{axis}
 \end{tikzpicture}
\end{center}

Значит, новая плотность вероятности выглядит так:
\begin{align*}
  f_{X \mid A}(x)  =\begin{cases}
    \frac{0.25}{0.4} = 0.625, x \in [1, 2) \\
    \frac{0.15}{0.4} = 0.375, x \in [2, 3) \\
    0, \text{ иначе.}
  \end{cases}
\end{align*}

\begin{center}
  \begin{tikzpicture}
   \begin{axis}[
   grid=major,
   ylabel={$f_{X \mid A}(x)$},
   xlabel={$x$}]
   
    \addplot[draw=red, draw=none, fill=red!20] coordinates
      {(0,0.25) (2,0.25)} \closedcycle;
    \addplot[draw=red, draw=none, fill=red!20] coordinates
      {(2,0.15) (3,0.15)} \closedcycle;
    \addplot[draw=red, draw=none, fill=red!20] coordinates
      {(3,0.35) (4,0.35)} \closedcycle;
    
    \addplot[draw=red, ultra thick] coordinates
      {(-1,0) (0,0)};
    \addplot[draw=red, ultra thick] coordinates
      {(0,0.25) (2,0.25)};
    \addplot[draw=red, ultra thick] coordinates
      {(2,0.15) (3,0.15)};
    \addplot[draw=red, ultra thick] coordinates
      {(3,0.35) (4,0.35)};
    \addplot[draw=red, ultra thick] coordinates
      {(4,0) (5,0)};

    \addplot[draw=blue, draw=none, fill=blue, fill opacity=0.2] coordinates
      {(1,0.625) (2,0.625)} \closedcycle;
    \addplot[draw=blue, draw=none, fill=blue, fill opacity=0.2] coordinates
      {(2,0.375) (3,0.375)} \closedcycle;
   
    \addplot[draw=blue, ultra thick] coordinates
      {(-1,0) (1,0)};
    \addplot[draw=blue, ultra thick] coordinates
      {(1,0.625) (2,0.625)};
    \addplot[draw=blue, ultra thick] coordinates
      {(2,0.375) (3,0.375)};
    \addplot[draw=blue, ultra thick] coordinates
      {(3,0) (5,0)};

    \node (exp) [above] at (axis cs:1.875,0) {};
   \end{axis}
   
   \node (label) at (2, -2) {Вот тут цетр масс};
   \draw [->] (label) -- (exp);
 \end{tikzpicture}
\end{center}  

\begin{align*}
  E(X \mid A) = \int_1^2 t \cdot 0.625 dt + \int_2^3 t \cdot 0.375 dt = 1.875
\end{align*}

\section{Беспамятство экспоненциального распределения}

Как уже говорилось, экспоненциальное распределение очень похоже на геометрическое. В том числе вот почему. Пусть продолжительность жизни лампочки $T$ следует $\Exp(\lambda)$. Следует ли поменять лампочку после того, как она проработала время $t$? Посмотрим, сколько она еще проживет, то есть распределение $T - t$ при условии $T \ge t$. 

\begin{align*}
  F_{(T - t) \mid T \ge t}(x) &= \Pr(T - t \ge x \mid T > t) = \frac{\Pr(T - t \ge x \cap T > t)}{\Pr(T > t)} \\
  &= \frac{\Pr(T\ge x + t)}{\Pr(T > t)} = \frac{e^{-\lambda(x + t)}}{e^{-\lambda t}} = e^{-\lambda x},  
\end{align*}
то есть распределение точно то же, как если мы заменим лампочку на новую.

\section{Полные вероятность и матожидание}

Напомним: пусть есть разбиение $\Omega$ на $\{A_i\}$ (не более, чем счетное), тогда

\begin{align*}
  \Pr(B) &= \Pr(A_1) \Pr(B \mid A_1) + \dots +  \Pr(A_n) \Pr(B \mid A_n) + \dots \\
  p_X(x) &= \Pr(A_1) p_{X \mid A_1}(x) + \dots + \Pr(A_n) p_{X \mid A_n}(x) + \dots
\end{align*}

Ничего не меняется и в непрерывном случае. Сначала функция распределения:
\begin{align*}
  F_X(x) = \Pr(X \le x) &= \Pr(A_1) \Pr(X \le x \mid A_1) + \dots + \Pr(A_n) \Pr(X \le x \mid A_n) + \dots \\
  &= \Pr(A_1) F_{X \mid A_1}(x) + \dots + \Pr(A_n) F_{X \mid A_n}(x) + \dots
\end{align*}

Дифференцируем, получаем:
\begin{align*}
  f_X(x) = \Pr(A_1) f_{X \mid A_1}(x) + \dots + \Pr(A_n) f_{X \mid A_n}(x) + \dots
\end{align*}

Умножаем на $x$ и интегрируем по всему $\R$:
\begin{align*}
  E(X) = \Pr(A_1) E(X \mid A_1) + \dots + \Pr(A_n) E(X \mid A_n) + \dots
\end{align*}

Пример (который уже был): 

\begin{align*}
  f_X(x)  =\begin{cases}
    0.25, x \in [0, 2) \\
    0.15, x \in [2, 3) \\
    0.35, x \in [3, 4] \\
    0, \text{ иначе.}
  \end{cases}
\end{align*}


\begin{center}
  \begin{tikzpicture}
   \begin{axis}[
   grid=major,
   ylabel={$f_{X}(x)$},
   xlabel={$x$}]
   
   \addplot[draw=blue, draw=none, fill=blue!20] coordinates
     {(0,0.25) (2,0.25)} \closedcycle;
   \addplot[draw=blue, draw=none, fill=blue!20] coordinates
     {(2,0.15) (3,0.15)} \closedcycle;
   \addplot[draw=blue, draw=none, fill=blue!20] coordinates
     {(3,0.35) (4,0.35)} \closedcycle;
   
   \addplot[draw=blue, ultra thick] coordinates
     {(-1,0) (0,0)};
   \addplot[draw=blue, ultra thick] coordinates
     {(0,0.25) (2,0.25)};
   \addplot[draw=blue, ultra thick] coordinates
     {(2,0.15) (3,0.15)};
   \addplot[draw=blue, ultra thick] coordinates
     {(3,0.35) (4,0.35)};
   \addplot[draw=blue, ultra thick] coordinates
     {(4,0) (5,0)};
   \end{axis}
 \end{tikzpicture}
\end{center}

Посчитаем матожидание

\begin{align*}
  E(X) &= \Pr(X \in [0, 2)) E(X \mid X \in [0, 2)) \\
  &+ \Pr(X \in [2, 3)) E(X \mid X \in [2, 3)) \\
  &+ \Pr(X \in [3, 4)) E(X \mid X \in [3, 4)) 
\end{align*}

Заметим, что на каждом отрезке матожидание -- это положение центра масс, то есть середина отрезка. Поэтому


\begin{align*}
  E(X) = 0.5 \cdot 1 + 0.15 \cdot 2.5 + 0.35 \cdot 3.5 = 2.1
\end{align*}

\end{document}